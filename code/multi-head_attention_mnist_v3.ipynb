{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multi-head_attention_mnist_v3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMx70H/uqWE5KarH+szLea6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IkXFEfF3Z2Vt","colab_type":"code","colab":{}},"source":["from keras.layers import Dense, Conv2D, Input, Lambda, Flatten\n","from keras.layers import Add, Reshape, MaxPooling2D, Concatenate, RepeatVector, Multiply, dot\n","from keras.models import Model\n","from keras import backend as K\n","\n","import numpy as np\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation\n","from keras.utils import np_utils\n","from keras.engine.topology import Layer\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMQpZPvDPEVl","colab_type":"code","colab":{}},"source":["def attention_util(x, y, axes, normalise=False):\n","  out = dot(x, y, axes=axes, normalize=normalize)\n","  out = tf.reduce_sum(out, axis=3)\n","  return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HuQREr5ibFpI","colab_type":"code","colab":{}},"source":["def main_attention(l=6*6, d=64*3 , dv=8*3, nv = 8):\n","\n","    x = Input(shape=(l,d))\n","    print(\"input shape - \", x.shape)\n","    v_in = Dense(d, activation='relu')(x)\n","    q_in = Dense(d, activation='relu')(x)\n","    k_in = Dense(d, activation='relu')(x)\n","    print(\"Project to linear space:\")\n","    print(\"v_in - \", v_in.shape)\n","    print(\"k_in - \", k_in.shape)\n","    print(\"q_in - \", q_in.shape)\n","\n","    v = Dense(nv*dv, activation = 'relu')(v_in)\n","    k = Dense(nv*dv, activation = 'relu')(k_in)\n","    q = Dense(nv*dv, activation = 'relu')(q_in)\n","    print(\"v - \", v.shape)\n","    print(\"k - \", k.shape)\n","    print(\"q - \", q.shape)\n","   \n","    v = Reshape([l,nv,dv])(v)  \n","    k = Reshape([l,nv,dv])(k)  \n","    q = Reshape([l,nv,dv])(q)\n","    print(\"after reshaping\")\n","    print(\"v - \", v.shape)\n","    print(\"k - \", k.shape)\n","    print(\"q - \", q.shape)\n","\n","    # att1 = dot([q,k], axes=(3,3), normalize=True)\n","    # att1 = tf.reduce_sum(att1, axis=3)\n","    att_layer = Lambda(lambda x : tf.reduce_sum(dot(x[0], x[1], axes=(3,3), normalize=True), axis=3))\n","    att1 = att_layer()([q,k])\n","    print(\"Dot prod q and k - \", att1.shape)\n","    att1 = K.softmax(att1, axis=-1)\n","    print(\"softmax - \", att1.shape)\n","\n","    att2 = dot([att1, v], axes=(3,2))\n","    att2 = tf.reduce_sum(att2, axis=3)\n","    print(\"Dot prod v and attention - \", att2.shape)\n","\n","    out = Reshape([l,d])(att2)\n","    print(\"After reshaping - \", out.shape)\n","    out = Add()([q_in, out])\n","    print(\"After adding - \", out.shape)\n","    #out = Dense(2 * d, activation='relu')(out)\n","    return Model(inputs=x, outputs=out)\n","    #return att_model\n","    # new = Multiply()([q,k])\n","    # new = Activation('softmax')(new)\n","   \n","    # new1 = Multiply()([new,v])\n","    # new1 = Reshape([l,d])(new1)\n","    # out = Add()([new1,x])\n","    # return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rFf3zcktoQyf","colab_type":"code","outputId":"6e55e112-ec42-44cb-c5b2-755514864c8a","executionInfo":{"status":"ok","timestamp":1583506205272,"user_tz":-330,"elapsed":1375,"user":{"displayName":"ADYASHA CHAKRAVARTY","photoUrl":"","userId":"14866636947365412664"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["nb_classes = 10\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","X_train = X_train.reshape(60000, 28,28,1)\n","X_test = X_test.reshape(10000, 28,28,1)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","print(\"Training matrix shape\", X_train.shape)\n","print(\"Testing matrix shape\", X_test.shape)\n","Y_train = np_utils.to_categorical(y_train, nb_classes)\n","Y_test = np_utils.to_categorical(y_test, nb_classes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["X_train original shape (60000, 28, 28)\n","y_train original shape (60000,)\n","Training matrix shape (60000, 28, 28, 1)\n","Testing matrix shape (10000, 28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"POmUNwd6oUjs","colab_type":"code","outputId":"8d8ae45f-e8be-4420-b86a-2d4b8aac8e7f","executionInfo":{"status":"error","timestamp":1583507203027,"user_tz":-330,"elapsed":1345,"user":{"displayName":"ADYASHA CHAKRAVARTY","photoUrl":"","userId":"14866636947365412664"}},"colab":{"base_uri":"https://localhost:8080/","height":548}},"source":["inp = Input((28, 28, 1), name='input_layer')\n","x = Conv2D(32,(2,2),activation='relu', padding='same')(inp)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Conv2D(64,(2,2),activation='relu')(x)\n","x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n","x = Conv2D(64*3,(2,2),activation='relu')(x)\n","x = Reshape([6*6,64*3])(x)  \n","att = main_attention(l=6*6, d=64*3 , dv=8*3, nv = 8)\n","out = att(x)\n","out = Dense(32, activation = 'relu')(out)\n","#x = Reshape([6,6,32])(x)  \n","x = Flatten()(out)\n","x = Dense(256, activation='relu')(x)\n","x = Dense(10, activation='softmax')(x)\n","\n","model = Model(input = inp, output = x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["input shape -  (?, 36, 192)\n","Project to linear space:\n","v_in -  (?, 36, 192)\n","k_in -  (?, 36, 192)\n","q_in -  (?, 36, 192)\n","v -  (?, 36, 192)\n","k -  (?, 36, 192)\n","q -  (?, 36, 192)\n","after reshaping\n","v -  (?, 36, 8, 24)\n","k -  (?, 36, 8, 24)\n","q -  (?, 36, 8, 24)\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-b7821c6f21e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-55-4ae9c180db71>\u001b[0m in \u001b[0;36mmain_attention\u001b[0;34m(l, d, dv, nv)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# att1 = tf.reduce_sum(att1, axis=3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0matt_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0matt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dot prod q and k - \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0matt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'inputs'"]}]},{"cell_type":"code","metadata":{"id":"9yGLqy5RogHM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}