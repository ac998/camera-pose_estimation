{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multi-head_attention_mnist_example_v1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMXA//N5e0oLep4hCZNQP/c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WHUNFYgIda4E","colab_type":"code","colab":{}},"source":["from keras.layers import Dense, Dropout,  Conv2D, Input, Lambda, Flatten, TimeDistributed\n","from keras.layers import Add, Reshape, MaxPooling2D, Concatenate, Embedding, RepeatVector, Multiply\n","from keras.models import Model\n","from keras import backend as K\n","\n","import numpy as np\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation\n","from keras.utils import np_utils\n","from keras.engine.topology import Layer\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WmTkMVN19KW","colab_type":"code","colab":{}},"source":["def main_attention(x, l=6*6, d=64*3 , dv=8*3, nv = 8):\n","   \n","    v = Dense(d, activation = 'relu')(x)\n","    k = Dense(d, activation = 'relu')(x)\n","    q = Dense(d, activation = 'relu')(x)\n","   \n","    v = Reshape([l,dv,nv])(v)  \n","    k = Reshape([l,dv,nv])(k)  \n","    q = Reshape([l,dv,nv])(q)\n","   \n","    new = Multiply()([q,k])\n","    new = Activation('softmax')(new)\n","   \n","    new1 = Multiply()([new,v])\n","    new1 = Reshape([l,d])(new1)\n","    out = Add()([new1,x])\n","   \n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRgQc9fM2Hma","colab_type":"code","colab":{}},"source":["def multi_head(l=6*6, d=64*3 , dv=8*3, nv = 8):\n","   \n","    input_img = Input(shape = (l,d))\n","   \n","    out_1 = main_attention(input_img, l=6*6, d=64*3 , dv=8*3, nv = 8)\n","    out_2 = main_attention(input_img, l=6*6, d=64*3 , dv=8*3, nv = 8)\n","    out = Concatenate(axis = 2)([out_1,out_2])\n","    att_model = Model(input = input_img, output = out)\n","    print(att_model.summary())\n","    return att_model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5VeW9TkmeHUY","colab_type":"code","colab":{}},"source":["'''\n","def MultiHeadsAttModel(l=8*8, d=512, dv=64, dout=512, nv = 8 ):\n","    v1 = Input(shape = (l, d))\n","    q1 = Input(shape = (l, d))\n","    k1 = Input(shape = (l, d))\n","\n","    v2 = Dense(dv*nv, activation = \"relu\")(v1)\n","    q2 = Dense(dv*nv, activation = \"relu\")(q1)\n","    k2 = Dense(dv*nv, activation = \"relu\")(k1)\n","\n","    v = Reshape([l, nv, dv])(v2)\n","    q = Reshape([l, nv, dv])(q2)\n","    k = Reshape([l, nv, dv])(k2)\n","        \n","    att = Lambda(lambda x: K.batch_dot(x[0],x[1] ,axes=[-1,-1]) / np.sqrt(dv),\n","                 output_shape=(l, nv, nv))([q,k])# l, nv, nv\n","    att = Lambda(lambda x:  K.softmax(x) , output_shape=(l, nv, nv))(att)\n","\n","    out = Lambda(lambda x: K.batch_dot(x[0], x[1],axes=[1,1]),  output_shape=(l, nv, dv))([att, v])\n","    out = Reshape([l, d])(out)\n","    \n","    out = Add()([out, q1])\n","\n","    out = Dense(dout, activation = \"relu\")(out)\n","\n","    return  Model(inputs=[q1,k1,v1], outputs=out)\n","\n","class NormL(Layer):\n","\n","    def __init__(self, **kwargs):\n","        super(NormL, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        # Create a trainable weight variable for this layer.\n","        self.a = self.add_weight(name='kernel', \n","                                      shape=(1,input_shape[-1]),\n","                                      initializer='ones',\n","                                      trainable=True)\n","        self.b = self.add_weight(name='kernel', \n","                                      shape=(1,input_shape[-1]),\n","                                      initializer='zeros',\n","                                      trainable=True)\n","        super(NormL, self).build(input_shape)  # Be sure to call this somewhere!\n","\n","    def call(self, x):\n","        eps = 0.000001\n","        mu = K.mean(x, keepdims=True, axis=-1)\n","        sigma = K.std(x, keepdims=True, axis=-1)\n","        ln_out = (x - mu) / (sigma + eps)\n","        return ln_out*self.a + self.b\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8az7ZGZceS8X","colab_type":"code","colab":{}},"source":["nb_classes = 10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WghsUjHJfXXo","colab_type":"code","outputId":"a4745fea-49f7-41c0-e69b-74221162d5ee","executionInfo":{"status":"ok","timestamp":1583431196834,"user_tz":-330,"elapsed":1938,"user":{"displayName":"ADYASHA CHAKRAVARTY","photoUrl":"","userId":"14866636947365412664"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["X_train original shape (60000, 28, 28)\n","y_train original shape (60000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"92U0sgvVfb2w","colab_type":"code","outputId":"1bb72c23-766d-4029-e5db-387a18722e4a","executionInfo":{"status":"ok","timestamp":1583431199135,"user_tz":-330,"elapsed":1337,"user":{"displayName":"ADYASHA CHAKRAVARTY","photoUrl":"","userId":"14866636947365412664"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["X_train = X_train.reshape(60000, 28,28,1)\n","X_test = X_test.reshape(10000, 28,28,1)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","print(\"Training matrix shape\", X_train.shape)\n","print(\"Testing matrix shape\", X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training matrix shape (60000, 28, 28, 1)\n","Testing matrix shape (10000, 28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fTCc5Ey0fqV9","colab_type":"code","colab":{}},"source":["Y_train = np_utils.to_categorical(y_train, nb_classes)\n","Y_test = np_utils.to_categorical(y_test, nb_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sDpyOQpQfxTC","colab_type":"code","outputId":"4680a161-6a60-4bf6-bd61-563855380d92","executionInfo":{"status":"ok","timestamp":1583431268665,"user_tz":-330,"elapsed":1654,"user":{"displayName":"ADYASHA CHAKRAVARTY","photoUrl":"","userId":"14866636947365412664"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["# inp = Input(shape = (28,28,1))\n","# x = Conv2D(32,(2,2),activation='relu', padding='same')(inp)\n","# x = MaxPooling2D(pool_size=(2, 2))(x)\n","# x = Conv2D(64,(2,2),activation='relu')(x)\n","# x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n","# x = Conv2D(64*3,(2,2),activation='relu')(x)\n","\n","# x = Reshape([6*6,64*3])(x)    \n","# att = MultiHeadsAttModel(l=6*6, d=64*3 , dv=8*3, dout=32, nv = 8 )\n","# x = att([x,x,x])\n","# x = Reshape([6,6,32])(x)   \n","# x = NormL()(x)\n","# x = Flatten()(x) \n","# x = Dense(256, activation='relu')(x)\n","# x = Dense(10, activation='softmax')(x)\n","inp = Input((28, 28, 1), name='input_layer')\n","x = Conv2D(32,(2,2),activation='relu', padding='same')(inp)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Conv2D(64,(2,2),activation='relu')(x)\n","x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n","x = Conv2D(64*3,(2,2),activation='relu')(x)\n","x = Reshape([6*6,64*3])(x)  \n","att = multi_head(l=6*6, d=64*3 , dv=8*3, nv = 8)\n","out = att(x)\n","out = Dense(32, activation = 'relu')(out)\n","#x = Reshape([6,6,32])(x)  \n","x = Flatten()(out)\n","x = Dense(256, activation='relu')(x)\n","x = Dense(10, activation='softmax')(x)\n","\n","model = Model(input = inp, output = x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n","  app.launch_new_instance()\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hJuNaHXrgIkM","colab_type":"code","outputId":"c00ae832-6674-4144-ea0a-bd0e847210fe","executionInfo":{"status":"ok","timestamp":1583431299803,"user_tz":-330,"elapsed":1128,"user":{"displayName":"ADYASHA CHAKRAVARTY","photoUrl":"","userId":"14866636947365412664"}},"colab":{"base_uri":"https://localhost:8080/","height":554}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_layer (InputLayer)     (None, 28, 28, 1)         0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 28, 28, 32)        160       \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 13, 13, 64)        8256      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 6, 6, 192)         49344     \n","_________________________________________________________________\n","reshape_5 (Reshape)          (None, 36, 192)           0         \n","_________________________________________________________________\n","model_1 (Model)              (None, 36, 384)           222336    \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 36, 32)            12320     \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1152)              0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 256)               295168    \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 10)                2570      \n","=================================================================\n","Total params: 590,154\n","Trainable params: 590,154\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ofeZ_HG23C31","colab_type":"code","outputId":"c324c0f4-5f25-4436-acc2-b79f5d754cce","executionInfo":{"status":"ok","timestamp":1583431329707,"user_tz":-330,"elapsed":1061,"user":{"displayName":"ADYASHA CHAKRAVARTY","photoUrl":"","userId":"14866636947365412664"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hgqvUnrV3KMp","colab_type":"code","outputId":"0539e160-2c37-4b19-ce63-84273341ca50","executionInfo":{"status":"ok","timestamp":1583432914636,"user_tz":-330,"elapsed":1556759,"user":{"displayName":"ADYASHA CHAKRAVARTY","photoUrl":"","userId":"14866636947365412664"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.fit(X_train, Y_train,\n","              batch_size=128, \n","              epochs=100,\n","              verbose=1,          \n","              validation_data=(X_test, Y_test)\n","             )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/100\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","60000/60000 [==============================] - 30s 496us/step - loss: 0.1994 - acc: 0.9384 - val_loss: 0.0766 - val_acc: 0.9756\n","Epoch 2/100\n","60000/60000 [==============================] - 15s 257us/step - loss: 0.0503 - acc: 0.9841 - val_loss: 0.0358 - val_acc: 0.9873\n","Epoch 3/100\n","60000/60000 [==============================] - 15s 255us/step - loss: 0.0337 - acc: 0.9894 - val_loss: 0.0314 - val_acc: 0.9905\n","Epoch 4/100\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.0258 - acc: 0.9922 - val_loss: 0.0304 - val_acc: 0.9901\n","Epoch 5/100\n","60000/60000 [==============================] - 15s 253us/step - loss: 0.0202 - acc: 0.9935 - val_loss: 0.0329 - val_acc: 0.9897\n","Epoch 6/100\n","60000/60000 [==============================] - 15s 252us/step - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0333 - val_acc: 0.9898\n","Epoch 7/100\n","60000/60000 [==============================] - 15s 252us/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0349 - val_acc: 0.9896\n","Epoch 8/100\n","60000/60000 [==============================] - 15s 248us/step - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0374 - val_acc: 0.9905\n","Epoch 9/100\n","60000/60000 [==============================] - 15s 248us/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0347 - val_acc: 0.9918\n","Epoch 10/100\n","60000/60000 [==============================] - 15s 250us/step - loss: 0.0109 - acc: 0.9961 - val_loss: 0.0346 - val_acc: 0.9910\n","Epoch 11/100\n","60000/60000 [==============================] - 15s 250us/step - loss: 0.0092 - acc: 0.9971 - val_loss: 0.0383 - val_acc: 0.9894\n","Epoch 12/100\n","60000/60000 [==============================] - 15s 250us/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.0474 - val_acc: 0.9883\n","Epoch 13/100\n","60000/60000 [==============================] - 15s 250us/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.0420 - val_acc: 0.9909\n","Epoch 14/100\n","60000/60000 [==============================] - 15s 249us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0347 - val_acc: 0.9909\n","Epoch 15/100\n","60000/60000 [==============================] - 15s 250us/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0392 - val_acc: 0.9904\n","Epoch 16/100\n","60000/60000 [==============================] - 15s 249us/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0398 - val_acc: 0.9900\n","Epoch 17/100\n","60000/60000 [==============================] - 15s 247us/step - loss: 0.0040 - acc: 0.9986 - val_loss: 0.0530 - val_acc: 0.9888\n","Epoch 18/100\n","60000/60000 [==============================] - 15s 248us/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0461 - val_acc: 0.9909\n","Epoch 19/100\n","60000/60000 [==============================] - 15s 255us/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0422 - val_acc: 0.9910\n","Epoch 20/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0413 - val_acc: 0.9921\n","Epoch 21/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0499 - val_acc: 0.9894\n","Epoch 22/100\n","60000/60000 [==============================] - 15s 256us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0397 - val_acc: 0.9923\n","Epoch 23/100\n","60000/60000 [==============================] - 15s 256us/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0516 - val_acc: 0.9889\n","Epoch 24/100\n","60000/60000 [==============================] - 15s 256us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0359 - val_acc: 0.9920\n","Epoch 25/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0432 - val_acc: 0.9905\n","Epoch 26/100\n","60000/60000 [==============================] - 16s 261us/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0435 - val_acc: 0.9912\n","Epoch 27/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0496 - val_acc: 0.9906\n","Epoch 28/100\n","60000/60000 [==============================] - 15s 257us/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0466 - val_acc: 0.9898\n","Epoch 29/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0382 - val_acc: 0.9916\n","Epoch 30/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0507 - val_acc: 0.9903\n","Epoch 31/100\n","60000/60000 [==============================] - 16s 264us/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0478 - val_acc: 0.9905\n","Epoch 32/100\n","60000/60000 [==============================] - 16s 264us/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0402 - val_acc: 0.9915\n","Epoch 33/100\n","60000/60000 [==============================] - 16s 267us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0551 - val_acc: 0.9894\n","Epoch 34/100\n","60000/60000 [==============================] - 16s 267us/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0497 - val_acc: 0.9918\n","Epoch 35/100\n","60000/60000 [==============================] - 16s 270us/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0535 - val_acc: 0.9896\n","Epoch 36/100\n","60000/60000 [==============================] - 16s 261us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0370 - val_acc: 0.9928\n","Epoch 37/100\n","60000/60000 [==============================] - 16s 259us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0447 - val_acc: 0.9917\n","Epoch 38/100\n","60000/60000 [==============================] - 16s 262us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0443 - val_acc: 0.9919\n","Epoch 39/100\n","60000/60000 [==============================] - 16s 259us/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0601 - val_acc: 0.9898\n","Epoch 40/100\n","60000/60000 [==============================] - 16s 259us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0494 - val_acc: 0.9913\n","Epoch 41/100\n","60000/60000 [==============================] - 16s 261us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0536 - val_acc: 0.9908\n","Epoch 42/100\n","60000/60000 [==============================] - 16s 261us/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0654 - val_acc: 0.9893\n","Epoch 43/100\n","60000/60000 [==============================] - 16s 259us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0469 - val_acc: 0.9922\n","Epoch 44/100\n","60000/60000 [==============================] - 16s 259us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0516 - val_acc: 0.9920\n","Epoch 45/100\n","60000/60000 [==============================] - 16s 267us/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0514 - val_acc: 0.9911\n","Epoch 46/100\n","60000/60000 [==============================] - 16s 270us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0506 - val_acc: 0.9918\n","Epoch 47/100\n","60000/60000 [==============================] - 16s 263us/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0673 - val_acc: 0.9899\n","Epoch 48/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0572 - val_acc: 0.9899\n","Epoch 49/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0495 - val_acc: 0.9927\n","Epoch 50/100\n","60000/60000 [==============================] - 16s 259us/step - loss: 5.9222e-04 - acc: 0.9999 - val_loss: 0.0642 - val_acc: 0.9903\n","Epoch 51/100\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0549 - val_acc: 0.9909\n","Epoch 52/100\n","60000/60000 [==============================] - 15s 257us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0670 - val_acc: 0.9901\n","Epoch 53/100\n","60000/60000 [==============================] - 15s 254us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0582 - val_acc: 0.9912\n","Epoch 54/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.0569 - val_acc: 0.9913\n","Epoch 55/100\n","60000/60000 [==============================] - 15s 256us/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0595 - val_acc: 0.9893\n","Epoch 56/100\n","60000/60000 [==============================] - 16s 260us/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0587 - val_acc: 0.9912\n","Epoch 57/100\n","60000/60000 [==============================] - 15s 257us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0515 - val_acc: 0.9927\n","Epoch 58/100\n","60000/60000 [==============================] - 16s 259us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0556 - val_acc: 0.9918\n","Epoch 59/100\n","60000/60000 [==============================] - 15s 256us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0555 - val_acc: 0.9904\n","Epoch 60/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0557 - val_acc: 0.9916\n","Epoch 61/100\n","60000/60000 [==============================] - 15s 252us/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0727 - val_acc: 0.9894\n","Epoch 62/100\n","60000/60000 [==============================] - 15s 247us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0546 - val_acc: 0.9913\n","Epoch 63/100\n","60000/60000 [==============================] - 15s 248us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0461 - val_acc: 0.9928\n","Epoch 64/100\n","60000/60000 [==============================] - 15s 250us/step - loss: 4.2026e-04 - acc: 0.9999 - val_loss: 0.0479 - val_acc: 0.9936\n","Epoch 65/100\n","60000/60000 [==============================] - 15s 250us/step - loss: 2.7281e-04 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 0.9937\n","Epoch 66/100\n","60000/60000 [==============================] - 15s 252us/step - loss: 2.7047e-04 - acc: 1.0000 - val_loss: 0.0465 - val_acc: 0.9936\n","Epoch 67/100\n","60000/60000 [==============================] - 15s 249us/step - loss: 2.7006e-04 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 0.9935\n","Epoch 68/100\n","60000/60000 [==============================] - 15s 250us/step - loss: 2.6979e-04 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 0.9934\n","Epoch 69/100\n","60000/60000 [==============================] - 15s 251us/step - loss: 2.6959e-04 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 0.9934\n","Epoch 70/100\n","60000/60000 [==============================] - 15s 246us/step - loss: 2.6943e-04 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 0.9934\n","Epoch 71/100\n","60000/60000 [==============================] - 15s 247us/step - loss: 2.6931e-04 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 0.9933\n","Epoch 72/100\n","60000/60000 [==============================] - 15s 249us/step - loss: 2.6921e-04 - acc: 1.0000 - val_loss: 0.0465 - val_acc: 0.9933\n","Epoch 73/100\n","60000/60000 [==============================] - 15s 247us/step - loss: 2.6912e-04 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 0.9933\n","Epoch 74/100\n","60000/60000 [==============================] - 15s 249us/step - loss: 2.6905e-04 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 0.9934\n","Epoch 75/100\n","60000/60000 [==============================] - 15s 249us/step - loss: 2.6900e-04 - acc: 1.0000 - val_loss: 0.0467 - val_acc: 0.9934\n","Epoch 76/100\n","60000/60000 [==============================] - 15s 250us/step - loss: 2.6895e-04 - acc: 1.0000 - val_loss: 0.0468 - val_acc: 0.9933\n","Epoch 77/100\n","60000/60000 [==============================] - 15s 250us/step - loss: 2.6892e-04 - acc: 1.0000 - val_loss: 0.0468 - val_acc: 0.9934\n","Epoch 78/100\n","60000/60000 [==============================] - 15s 256us/step - loss: 2.6888e-04 - acc: 1.0000 - val_loss: 0.0469 - val_acc: 0.9935\n","Epoch 79/100\n","60000/60000 [==============================] - 16s 265us/step - loss: 2.6886e-04 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 0.9935\n","Epoch 80/100\n","60000/60000 [==============================] - 16s 269us/step - loss: 2.6884e-04 - acc: 1.0000 - val_loss: 0.0471 - val_acc: 0.9935\n","Epoch 81/100\n","60000/60000 [==============================] - 16s 264us/step - loss: 2.6882e-04 - acc: 1.0000 - val_loss: 0.0472 - val_acc: 0.9935\n","Epoch 82/100\n","60000/60000 [==============================] - 16s 270us/step - loss: 2.6881e-04 - acc: 1.0000 - val_loss: 0.0473 - val_acc: 0.9936\n","Epoch 83/100\n","60000/60000 [==============================] - 16s 260us/step - loss: 2.6880e-04 - acc: 1.0000 - val_loss: 0.0474 - val_acc: 0.9936\n","Epoch 84/100\n","60000/60000 [==============================] - 15s 258us/step - loss: 2.6879e-04 - acc: 1.0000 - val_loss: 0.0475 - val_acc: 0.9936\n","Epoch 85/100\n","60000/60000 [==============================] - 16s 259us/step - loss: 2.6878e-04 - acc: 1.0000 - val_loss: 0.0476 - val_acc: 0.9936\n","Epoch 86/100\n","60000/60000 [==============================] - 16s 261us/step - loss: 2.6878e-04 - acc: 1.0000 - val_loss: 0.0478 - val_acc: 0.9936\n","Epoch 87/100\n","60000/60000 [==============================] - 16s 260us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.0479 - val_acc: 0.9936\n","Epoch 88/100\n","60000/60000 [==============================] - 15s 256us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.0481 - val_acc: 0.9936\n","Epoch 89/100\n","60000/60000 [==============================] - 16s 260us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 0.9937\n","Epoch 90/100\n","60000/60000 [==============================] - 16s 260us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0483 - val_acc: 0.9937\n","Epoch 91/100\n","60000/60000 [==============================] - 16s 261us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0485 - val_acc: 0.9936\n","Epoch 92/100\n","60000/60000 [==============================] - 16s 263us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 0.9936\n","Epoch 93/100\n","60000/60000 [==============================] - 16s 263us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 0.9937\n","Epoch 94/100\n","60000/60000 [==============================] - 16s 260us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0490 - val_acc: 0.9937\n","Epoch 95/100\n","60000/60000 [==============================] - 16s 263us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0492 - val_acc: 0.9938\n","Epoch 96/100\n","60000/60000 [==============================] - 16s 261us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 0.9939\n","Epoch 97/100\n","60000/60000 [==============================] - 16s 262us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 0.9939\n","Epoch 98/100\n","60000/60000 [==============================] - 16s 263us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 0.9939\n","Epoch 99/100\n","60000/60000 [==============================] - 15s 257us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 0.9939\n","Epoch 100/100\n","60000/60000 [==============================] - 15s 253us/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 0.9939\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb6c7616710>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"N_Lcddrg3OAy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}